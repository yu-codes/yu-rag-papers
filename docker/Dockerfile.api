############################################################
#  Stage 1 ── builder  (安裝相依套件到 /root/.local)
############################################################
FROM python:3.11-slim AS builder
WORKDIR /code

# ❶ 先複製兩支 requirements
COPY requirements/requirements.core.txt requirements/requirements.api.txt ./

# ❷ 先裝共用依賴，再裝 API 專屬依賴
#    --no-cache-dir 可省下 pip cache，縮小映像
RUN pip install --user --no-cache-dir -r requirements.core.txt \
 && pip install --user --no-cache-dir -r requirements.api.txt

############################################################
#  Stage 2 ── runtime  (實際執行容器)
############################################################
FROM python:3.11-slim

# 不要把 log buffer 在記憶體；把 pip user bin 加進 PATH
ENV PYTHONUNBUFFERED=1 \
    PATH=/root/.local/bin:$PATH

WORKDIR /code

# ❸ 複製已安裝好的 site-packages & CLI
COPY --from=builder /root/.local /root/.local

# ❹ 複製專案原始碼
COPY . .

# ❺ 預先把 TinyLlama GGUF (~1 GiB) 放進映像
#    如果你在 CI/CD 已做 cache，可移除此段改為快取層
RUN mkdir -p /code/models \
 && curl -L -o /code/models/tinyllama-q4_K_M.gguf \
      https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf

EXPOSE 8000

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
